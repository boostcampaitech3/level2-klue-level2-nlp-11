{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c67dd3c-d2d0-4447-9acb-f6d003a0dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 03:36:46.798484: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoConfig,BigBirdModel, BigBirdPreTrainedModel, RobertaPreTrainedModel\n",
    "from embeddings import *\n",
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, AutoModelForTokenClassification, Trainer, TrainingArguments, RobertaConfig, RobertaTokenizer, RobertaForSequenceClassification, BertTokenizer\n",
    "from load_data import *\n",
    "from entity_model import *\n",
    "from embeddings import *\n",
    "import torch.nn.functional as F\n",
    "from transformers.activations import ACT2FN\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb91769-9117-4bf2-8d6a-e806cbe0ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Embedding_Model(BigBirdPreTrainedModel):\n",
    "    def __init__(self, config, dropout_rate):\n",
    "        super(Entity_Embedding_Model, self).__init__(config)\n",
    "        self.model = AutoModel.from_pretrained('monologg/kobigbird-bert-base')\n",
    "        self.model_config = config\n",
    "        self.model.embeddings =Entity_Embeddings(config)\n",
    "        self.model_config.num_labels = 30\n",
    "        self.num_labels = 30\n",
    "\n",
    "        #self.cls_fc_layer = FCLayer(self.config.hidden_size, self.config.hidden_size, dropout_rate)\n",
    "        #self.entity_fc_layer1 = FCLayer(self.config.hidden_size, self.config.hidden_size, dropout_rate)\n",
    "        #self.entity_fc_layer2 = FCLayer(self.config.hidden_size, self.config.hidden_size, dropout_rate)\n",
    "\n",
    "        #self.label_classifier = FCLayer(\n",
    "        #    self.config.hidden_size * 3,\n",
    "        #    self.config.num_labels,\n",
    "        #    dropout_rate,\n",
    "        #    use_activation=False\n",
    "        #)\n",
    "        self.classifier = ClassificationHead(config)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask,token_type_ids, sub_mask, obj_mask, labels):\n",
    "        outputs = self.model(\n",
    "            input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids\n",
    "        )\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        \n",
    "        logits = self.classifier(sequence_output,sub_mask,obj_mask)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        output = (logits,) + outputs[2:]\n",
    "        return ((loss,) + output) if loss is not None else output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec648a4f-12f0-46ac-a628-bddefb9f84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.config = config\n",
    "    \n",
    "    def entity_features(self,features,sub_mask,obj_mask):\n",
    "        entity=[]\n",
    "        for i in range(len(features)):\n",
    "            sub_start = sub_mask[i].tolist().index(7)\n",
    "            sub_end = sub_mask[i].tolist().index(8)\n",
    "            obj_start = obj_mask[i].tolist().index(9)\n",
    "            obj_end = obj_mask[i].tolist().index(10)\n",
    "            total = (features[i,sub_start,:]*2+features[i,sub_end,:]*2+features[i,obj_start,:]+features[i,obj_end,:])/6\n",
    "            entity.append(total.tolist())\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        entity = torch.tensor(entity).to(device)\n",
    "        return entity\n",
    "    \n",
    "    def forward(self, features, sub_mask,obj_mask, **kwargs):\n",
    "        x = self.entity_features(features,sub_mask,obj_mask)\n",
    "          # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = ACT2FN[self.config.hidden_act](x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5193f5ab-e165-448d-aa07-d19385193773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_num(label):\n",
    "  num_label = []\n",
    "  with open('dict_label_to_num.pkl', 'rb') as f:\n",
    "    dict_label_to_num = pickle.load(f)\n",
    "  for v in label:\n",
    "    num_label.append(dict_label_to_num[v])\n",
    "  return num_label\n",
    "MODEL_NAME = 'monologg/kobigbird-bert-base'\n",
    "model_config =  AutoConfig.from_pretrained(MODEL_NAME)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bebbb6d-1a18-4984-a9ee-0190e11fe031",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'monologg/kobigbird-bert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained('/opt/ml/code/vocabs')\n",
    "train_dataset = load_data(\"/opt/ml/dataset/train/train.csv\")\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "\n",
    "tokenized_train = tokenized_dataset(train_dataset, tokenizer)\n",
    "\n",
    "RE_train_dataset = RE_Dataset(tokenized_train, train_label)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_config =  AutoConfig.from_pretrained(MODEL_NAME)\n",
    "model_config.num_labels = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86e8bca3-0ce2-4d25-a707-3b87b4004865",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenized_train['input_ids'][:10].to(device)\n",
    "attention_mask = tokenized_train['attention_mask'][:10].to(device)\n",
    "token_type_ids = tokenized_train['token_type_ids'][:10].to(device)\n",
    "sub_mask = tokenized_train['sub_mask'][:10].to(device)\n",
    "obj_mask = tokenized_train['obj_mask'][:10].to(device)\n",
    "labels = torch.tensor(train_label[:10]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a017f8-2a74-48d8-9f86-88b95bb312e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Entity_Embedding_Model(model_config,0.1)\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model.parameters\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8023fde1-81d3-4ae3-a761-64b911420dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 238 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0301,  0.1847],\n",
       "        [-0.0666,  0.1457],\n",
       "        [-0.0465,  0.1733],\n",
       "        [-0.0672,  0.1788],\n",
       "        [-0.0047,  0.1328],\n",
       "        [-0.0210,  0.1808],\n",
       "        [-0.0145,  0.1808],\n",
       "        [-0.0612,  0.1117],\n",
       "        [-0.0471,  0.1687],\n",
       "        [-0.0673,  0.1287]], device='cuda:0', grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs=model(input_ids = input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412df958-0358-4e5e-8e36-72de56c48604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 238 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.3712, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       " tensor([[-9.4556e-03, -2.4930e-02, -1.2922e-01, -7.7817e-02, -1.4273e-01,\n",
       "           4.5376e-02, -3.1409e-02, -1.6661e-01, -6.8012e-02,  1.5956e-02,\n",
       "           7.0293e-02, -8.5864e-02, -8.9937e-02, -1.1379e-01,  5.0766e-02,\n",
       "          -1.3515e-01,  3.1258e-02,  2.5222e-02,  2.2826e-02, -2.3527e-02,\n",
       "          -3.0600e-02,  2.1539e-01, -4.8287e-02, -1.1107e-01, -1.5114e-01,\n",
       "           1.4262e-01,  6.6954e-02,  2.7644e-02, -2.1801e-02,  2.1343e-02],\n",
       "         [ 3.1784e-02, -4.1267e-02, -8.0203e-02, -1.0629e-01, -2.3796e-01,\n",
       "          -1.4544e-02, -4.2640e-02, -2.2849e-01, -4.4176e-02, -5.0316e-03,\n",
       "           1.7746e-02, -1.4417e-01, -2.5458e-02, -1.1951e-01, -6.4889e-02,\n",
       "          -5.7664e-02, -3.3172e-02, -2.6596e-02,  1.9691e-02,  1.0580e-02,\n",
       "           4.2508e-02,  2.6667e-01,  2.7354e-02, -1.3545e-01, -1.3274e-01,\n",
       "           1.5948e-01,  5.3535e-02,  1.5847e-02, -1.3300e-02,  1.9433e-02],\n",
       "         [ 1.0473e-01,  1.4868e-03, -7.5007e-02, -1.2960e-01, -1.8650e-01,\n",
       "           5.6760e-02, -7.4420e-02, -1.6692e-01, -7.4019e-02,  5.0608e-05,\n",
       "           9.0469e-02, -9.0128e-02, -8.3515e-02, -1.5724e-01, -5.3199e-02,\n",
       "          -9.2992e-02,  3.3513e-02,  8.6620e-02, -2.6730e-03, -9.6385e-02,\n",
       "           2.1406e-03,  2.4374e-01,  5.1144e-02, -5.7934e-02, -2.1376e-01,\n",
       "           9.2141e-02, -6.0951e-02, -5.0178e-02, -7.3914e-02,  1.6612e-02],\n",
       "         [ 5.9486e-02, -1.2585e-02, -1.1078e-01, -1.0572e-01, -1.3077e-01,\n",
       "           4.8659e-02, -8.1054e-02, -2.2331e-01, -9.3715e-02,  4.0582e-02,\n",
       "           1.0523e-01, -7.9417e-02, -1.1466e-01, -8.3445e-02, -4.8762e-02,\n",
       "          -1.2789e-01, -2.7807e-02,  2.1204e-02,  7.6388e-02, -4.8570e-02,\n",
       "          -1.6204e-02,  2.2372e-01,  3.8891e-02, -8.1657e-02, -2.2638e-01,\n",
       "           1.3271e-01, -1.7870e-02,  8.4110e-02, -3.6433e-02,  1.4479e-02],\n",
       "         [ 7.9649e-02, -6.5908e-02, -1.6651e-01, -1.8527e-01, -1.1206e-01,\n",
       "           5.5980e-02, -9.6003e-02, -1.5610e-01, -3.2827e-02,  1.1026e-01,\n",
       "          -4.0086e-02, -1.1715e-01, -5.4246e-02, -1.2753e-01,  5.2643e-02,\n",
       "          -1.3310e-01,  2.1856e-02,  1.2053e-02,  1.5459e-02,  4.4659e-02,\n",
       "           1.3480e-02,  1.6831e-01,  5.9474e-03, -1.0256e-01, -1.3692e-01,\n",
       "           1.1860e-01,  2.6646e-02, -2.4368e-02, -1.1070e-01, -3.1670e-02],\n",
       "         [ 7.4633e-02,  7.7017e-02, -7.2437e-03, -1.3555e-01, -9.1938e-02,\n",
       "           1.4970e-03, -9.1360e-02, -1.2774e-01, -9.8332e-02,  2.9923e-02,\n",
       "           7.4198e-02, -4.0087e-02, -8.3173e-02,  6.5172e-03, -7.0047e-02,\n",
       "          -2.9791e-02, -1.5595e-02, -6.2370e-02, -5.0668e-02, -6.3775e-02,\n",
       "           2.0328e-02,  1.1058e-01,  3.4772e-02, -1.0895e-01, -1.3655e-01,\n",
       "           1.3957e-01,  1.1523e-01,  6.6892e-02, -8.1093e-03, -9.9066e-02],\n",
       "         [ 4.4625e-02, -3.8745e-02, -3.4637e-02, -1.0947e-01, -1.9552e-01,\n",
       "           9.0842e-02, -1.1423e-01, -1.7882e-01, -7.3137e-02,  3.3955e-02,\n",
       "           7.8189e-02, -1.5251e-01, -9.7652e-03, -3.2102e-02, -4.9979e-02,\n",
       "          -1.1762e-01,  5.7633e-02,  9.5675e-02,  3.6998e-02, -8.6164e-03,\n",
       "          -1.0035e-01,  1.6021e-01,  4.8312e-03, -1.0631e-01, -1.8022e-01,\n",
       "           9.3388e-02,  8.0618e-02,  1.7950e-02, -5.5558e-02,  4.3398e-02],\n",
       "         [ 2.4320e-02,  2.4027e-02, -4.3542e-02, -8.5929e-02, -2.3385e-01,\n",
       "           3.4460e-02, -3.1683e-02, -1.1742e-01, -1.4662e-02,  6.1830e-02,\n",
       "           4.3818e-02, -5.8562e-02, -1.3752e-01, -4.4081e-02, -1.2904e-01,\n",
       "          -1.0620e-01, -1.2691e-01, -6.2944e-02,  1.1852e-02, -3.5241e-02,\n",
       "           2.9461e-02,  1.2770e-01,  1.5411e-02, -4.5576e-02, -1.0736e-01,\n",
       "           1.8959e-01, -7.0735e-04, -1.1799e-02,  3.8225e-03, -1.0059e-01],\n",
       "         [ 7.9830e-02, -3.0521e-02, -1.2096e-01, -1.3594e-01, -1.4341e-01,\n",
       "           6.2339e-02, -8.1784e-02, -1.5406e-01, -4.6281e-02,  9.4287e-02,\n",
       "           2.0993e-02, -6.8977e-02, -1.0006e-01, -1.0500e-01, -6.3163e-02,\n",
       "          -1.8645e-01, -5.5129e-03,  2.6573e-02,  4.8588e-02, -5.7496e-02,\n",
       "          -2.7161e-02,  1.7307e-01,  5.0273e-03, -1.1264e-01, -1.0448e-01,\n",
       "           1.1253e-01,  2.4781e-02,  2.9865e-02, -1.7610e-02, -1.6585e-02],\n",
       "         [ 1.9968e-02, -7.5521e-02, -8.5732e-02, -1.1589e-01, -2.3829e-01,\n",
       "           3.5755e-02, -1.1816e-01, -1.1697e-01, -6.7221e-02,  9.9495e-02,\n",
       "           5.3474e-02, -9.9748e-02, -8.4974e-02, -1.3651e-01, -2.4443e-02,\n",
       "          -1.7652e-01, -4.4955e-02,  4.2621e-02,  6.9238e-02, -2.2583e-02,\n",
       "          -3.1894e-03,  1.5272e-01, -2.5582e-02, -1.1225e-01, -1.6201e-01,\n",
       "           1.1091e-01, -1.0943e-02,  3.3130e-02, -2.0309e-02,  1.1538e-03]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs=model(input_ids = input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,sub_mask=sub_mask, obj_mask=obj_mask,labels=labels)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d58ea-64b2-49f3-92c1-c2f68bd720f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
